<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Projects — Yanqing Wu</title>

  <link rel="stylesheet" href="static/css/main.css?v=desert1">

  <!-- Google Analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-89371373-1', 'auto');
    ga('send', 'pageview');
  </script>
</head>
<body>

  <nav class="site-nav" role="navigation" aria-label="Primary">
    <ul>
      <li><a href="index.html">Home</a></li>
      <li><a href="projects.html" aria-current="page">Projects</a></li>
      <li><a href="https://blog.yanqingwu.com/" target="_blank" rel="noopener">(old) Blog</a></li>
    </ul>
  </nav>

  <section id="projects">
    <div class="project">
      <img src="static/img/Belludum-logo-blue-red.svg" alt="Project Logo" />
      <div class="project-content">
        <h3>Simulation-Driven Web Game (Stealth project; WIP)</h3>
        <p>
          A real-time, military-themed, multiplayer, semi-automation/incremental webgame.
          Designed for maintainability, expandability, and performance — built entirely from scratch with no templates.
        </p>
        <p>
          I designed and implemented both front-end and back-end systems, including user authentication,
          language localization, and gameplay logic — all while self-learning full-stack development and Vue.
        </p>
        <ul class="tools">
          <li><strong>Vue 3 + Vite</strong>: Reactive front-end framework with lightning-fast build system</li>
          <li><strong>TypeScript</strong>: Static typing for code robustness and maintainability</li>
          <li><strong>Pinia</strong>: Centralized state management for UI/data sync</li>
          <li><strong>BEM CSS</strong>: Structured CSS for consistent styling</li>
          <li><strong>UI/UX design</strong>: Custom layout for dashboard and card interface</li>

          <li><strong>Node.js</strong>: Server logic and API endpoints</li>
          <li><strong>MongoDB Atlas</strong>: Cloud-hosted database for users, teams, and game state</li>
          <li><strong>JWT Auth</strong>: Secure user authentication</li>
          <li><strong>CORS config</strong>: Safe cross-origin API calls</li>

          <li><strong>WebSocket</strong>: Real-time multiplayer chat and game state updates</li>
          <li><strong>Axios</strong>: Standard API requests</li>
          <li><strong>Browser storage</strong>: Persistent user settings and localization</li>

          <li><strong>Jest</strong>: Unit tests</li>
          <li><strong>GitHub Actions</strong>: CI/CD</li>

          <li><strong>Core game design</strong>: Real-time sim engine, progress bars, idle/active hybrid</li>
          <li><strong>Anti-hacking logic</strong>: Defensive coding and validation</li>
          <li><strong>User system</strong>: Account, login, progress tracking</li>
          <li><strong>Resource system</strong>: Mining, construction, conversion, storage</li>
          <li><strong>Dashboard</strong>: Teams, missions, reports</li>

          <li><strong>Design thinking</strong>: Future-proofing, reusability, coherence</li>
          <li><strong>vibe-coding</strong>: Accelerated development using code suggestions</li>
        </ul>
      </div>
    </div>

    <div class="project">
      <img src="static/img/FillGame.png" alt="Fill-Game screenshot" />
      <div class="project-content">
        <h3>Heuristic Search: Fill-Game (Adversarial Fillomino) <a href="https://github.com/pwyq/Fill-Game" target="_blank" rel="noopener">[GitHub]</a><a></a></h3>
        <p>
          A two-player, adversarial version of Fillomino—built with heuristic search algorithms to support both PvE and PvP play.
        </p>
        <p>
          Implemented in modern C++ (with a Qt GUI), and featuring a variety of search strategies—Depth-First Proof Number Search (DFPN), Proof Number Search (PNS), Minimax & Negamax (each with alpha-beta pruning and transposition tables), plus Monte Carlo Tree Search (MCTS).
        </p>
        <ul class="tools">
          <li><strong>C++ 20</strong></li>
          <li><strong>Qt</strong> (cross-platform GUI)</li>
          <li><strong>DFPN, PNS</strong>: Strategic search planning</li>
          <li><strong>Minimax / Negamax</strong> w/ alpha-beta pruning & transposition tables</li>
          <li><strong>MCTS</strong>: Probabilistic, long-horizon planning</li>
          <li><strong>Cross-machine & local play</strong></li>
          <li><strong>Unit tests</strong> & performance tuning</li>
          <li><strong>Profiler</strong>: Valgrind, KCachegrind</li>
        </ul>
      </div>
    </div>

    <div class="project">
      <img src="static/img/IRB2600_moving_in_RobotStudio.gif" alt="IRB2600 moving in RobotStudio" />
      <div class="project-content">
        <h3>Dual Simulation: IRB2600 with ABB RobotStudio and CoppeliaSim (V-rep)</h3>
        <p>
          A simulation project demonstrating motion planning and execution for the ABB IRB2600 industrial robot arm.
          Developed using a mix of scripting and simulation tools to bridge virtual prototyping with real-world robotics workflows.
        </p>
        <p>
          The work included creating robot motion sequences, integrating with ABB RobotStudio for visualization, and
          using CoppeliaSim (formerly V-REP) for simulation and control logic testing on Ubuntu.
        </p>
        <ul class="tools">
          <li><strong>Python</strong>: Control scripts and data handling</li>
          <li><strong>Lua</strong>: Embedded scripting for CoppeliaSim (V-REP)</li>
          <li><strong>ABB RobotStudio</strong>: Industrial robot simulation and programming</li>
          <li><strong>CoppeliaSim (V-REP)</strong>: Physics-based robot simulation</li>
          <li><strong>Ubuntu</strong>: Development and runtime environment</li>
        </ul>
      </div>
    </div>

    <div class="project">
      <img src="static/img/viwistar.gif" alt="IRB2600 welding task simulation" />
      <div class="project-content">
        <h3>Reinforcement Learning: IRB2600 Welding Task Simulation</h3>
        <p>
          A simulation of an ABB IRB2600 robot executing a welding operation in a virtual environment.
          The project focused on task-specific motion planning, welding path generation, and fine-tuning
          joint trajectories for smooth and accurate operation.
        </p>
        <p>
          Combined industrial simulation software with scripting to automate and visualize welding processes before deployment. I also
          benchmarked reinforcement learning approaches — <strong>Proximal Policy Optimization (PPO)</strong> and
          <strong>Soft Actor-Critic (SAC)</strong> — to evaluate their performance in learning efficient welding paths.
        </p>
        <ul class="tools">
          <li><strong>RL Algorithms</strong>: PPO, SAC</li>
          <li><strong>Python</strong>: Welding path scripting, RL benchmarking</li>
          <li><strong>Lua</strong>: Custom motion control in CoppeliaSim (V-REP)</li>
          <li><strong>CoppeliaSim (V-REP)</strong>: Kinematics and task validation</li>
          <li><strong>Ubuntu</strong>: Development and runtime environment</li>
        </ul>
      </div>
    </div>
    
    <div class="project">
      <video controls autoplay muted loop playsinline>
        <source src="static/img/OMPL_LazyPRM_Obstacle_Avoidance_demo.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
      <div class="project-content">
        <h3>OMPL LazyPRM Obstacle Avoidance</h3>
        <p>
          A motion planning demo using the <strong>Open Motion Planning Library (OMPL)</strong> with the LazyPRM algorithm
          to navigate around obstacles. Demonstrates efficient graph-based planning for environments with complex geometry.
        </p>
        <ul class="tools">
          <li><strong>OMPL</strong>: LazyPRM motion planning</li>
          <li><strong>Python</strong>: Planning orchestration and visualization</li>
          <li><strong>Ubuntu</strong>: Development and runtime environment</li>
        </ul>
      </div>
    </div>

    <div class="project">
      <video controls autoplay muted loop playsinline>
        <source src="static/img/husky_phase1.mp4" type="video/mp4">
      </video>

      <div class="project-content">
        <h3>Husky UGV — Teleop & Camera Perception (Gazebo + RViz)</h3>
        <p>
          A simulation and control stack for Clearpath’s Husky UGV: keyboard teleoperation in Gazebo with live camera
          streams visualized in RViz. Includes topic wiring, launch files, and a minimal perception pipeline for
          testing navigation behaviors in a sandboxed environment.
        </p>
        <ul class="tools">
          <li><strong>ROS</strong>: node graph, topics, launch files</li>
          <li><strong>Gazebo</strong>: physics simulation, Husky model/plug-ins</li>
          <li><strong>RViz</strong>: visualization (camera/image topics, TF, robot model)</li>
          <li><strong>teleop_twist_keyboard</strong>: WASD keyboard control</li>
          <li><strong>Camera input</strong>: Gazebo camera / USB cam via <code>image_transport</code></li>
          <li><strong>Ubuntu</strong>: development & runtime</li>
          <li><strong>rosbag</strong>: data capture & replay (optional)</li>
          <li><strong>URDF/Xacro</strong>: robot model tweaks (optional)</li>
        </ul>
      </div>
    </div>

    <div class="project">
      <div class="video-wrapper">
        <iframe
          src="https://www.youtube.com/embed/1bRu2PWA9b8"
          title="BobaTron — Bubble Tea Self-Serving Machine"
          frameborder="0"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
          allowfullscreen>
        </iframe>
      </div>

      <div class="project-content">
        <h3>BobaTron — Bubble Tea Self-Serving Machine</h3>
        <p>
          Fully automated, tablet-operated bubble tea machine integrating dispensing, assembly/delivery, power,
          micro-controller, and user interaction subsystems. Built to cut wait time and ensure taste consistency,
          with precise feedback-controlled dispensing and contact-less mixing.
        </p>
        <p>
          Highlights: load-cell feedback loop with pumps & Archimedes screw for accurate dosing; orbital shaker
          for hygienic mixing; tablet UI with Wi-Fi control; multi-Arduino network over I²C. The prototype meets
          key specs and produces a drink in ~75 seconds; the milk module actively cools from ~9.5 °C to ~3 °C
          in ~25 minutes.
        </p>
        <ul class="tools">
          <li><strong>Control</strong>: Multi-Arduino network (I²C), ESP32 Wi-Fi server, tablet UI</li>
          <li><strong>Dispensing</strong>: Diaphragm & peristaltic pumps, Archimedes screw, load-cell feedback</li>
          <li><strong>Assembly/Mixing</strong>: Conveyor & cup dispenser, orbital shaker (contact-less)</li>
          <li><strong>Power/Thermal</strong>: Regulated DC rails, Peltier cooling with temperature feedback</li>
          <li><strong>Performance</strong>: ≈70 sec/drink;</li>
          <li><strong>Cost</strong>: Prototype ≈ C$1,500 (under C$4,000 target)</li>
        </ul>
      </div>
    </div>

    <div class="project">
      <img src="static/img/netflix.png" alt="Netflix Challenge — Movie Rating Prediction" />
      <div class="project-content">
        <h3 class="project-title">Netflix Challenge — Movie Rating Prediction</h3>
        <p class="project-description">
          Developed an <strong>Item-Item Collaborative Filtering</strong> recommendation algorithm to predict movie ratings, achieving a 
          minimum RMSE of 0.84991 on the Kaggle leaderboard <strong>(rank 1/250+)</strong>.  
          The system was trained on nearly 1 million ratings from ~6 thousands users for ~4 thousands movies, using user demographics 
          (gender, age, profession) and movie metadata (title, release year).
        </p>
        <ul class="tools">
          <li><strong>Item-Item Collaborative Filtering</strong>: Implemented Pearson correlation (centered cosine similarity) with <em>Python, NumPy, Pandas</em>.</li>
          <li><strong>Parameter Optimization</strong>: Tuned nearest neighbors <code>N</code>, applied rating capping, and tested dynamic <code>N</code> selection.</li>
          <li><strong>Cold-Start Handling</strong>: Applied local deviation adjustment to improve predictions for new items/users.</li>
          <li><strong>Performance Evaluation</strong>: Generated Kaggle submissions via <em>Kaggle API</em> for RMSE-based scoring on held-out datasets.</li>
        </ul>
      </div>
    </div>

    <div class="project">
      <img src="static/img/wgviewer.png" alt="Warship Girls Viewer" />

      <div class="project-content">
        <h3 class="project-title">
          WGViewer — Game Automation & GUI Tool for Warship Girls
          <a href="https://github.com/WarshipGirls/WGViewer" target="_blank" rel="noopener">[GitHub]</a>
          <a href="https://github.com/WarshipGirls/WGViewer/tree/master/screenshots" target="_blank" rel="noopener">
            [More Screenshots]
          </a>
        </h3>
        <p class="project-description">
          Developed a cross-platform GUI tool for <em>Warship Girls</em>, a popular mobile game in Asia, enabling 
          advanced automation and in-depth game data management. 
          The project reverse-engineered and integrated with the game’s API to provide full automated gameplay, 
          equipment management, and resource optimization features. 
          Achieved <strong>50,000+ downloads</strong> from Chinese gaming forums.
        </p>
        <ul class="tools">
          <li><strong>GUI Development</strong>: Built an intuitive, cross-platform interface using <em>PyQt</em>.</li>
          <li><strong>Game API Reverse Engineering</strong>: Automated gameplay, resource/equipment tracking, and event handling.</li>
          <li><strong>Automation Engine</strong>: Designed routines for fully unattended daily tasks, battles, and upgrades.</li>
          <li><strong>Version Management</strong>: Created modular architecture to quickly adapt to frequent game updates.</li>
          <li><strong>CI/CD</strong>: Set up GitHub Actions for automated builds and releases.</li>
          <li><strong>Asset Organization</strong>: Structured resources for images, configs, and logs for maintainability.</li>
          <li><strong>Performance Optimization</strong>: Improved memory and network efficiency for long-running sessions.</li>
        </ul>
      </div>
    </div>


    <div class="project">
      <img src="static/img/mhnow-automation.png" alt="Monster Hunter NOW automation" />
      <div class="project-content">
        <h3>Mobile Game Automation & Reverse Engineering</h3>
        <p>
          A personal deep-dive into automation and memory-level reverse engineering of a real-time AR ARPG,
          <em>Monster Hunter NOW</em> (from Pokemon Go company). Explored mobile system behavior, game memory, and scripting logic.
        </p>
        <ul class="tools">
          <li><strong>OpenCV + Vysor:</strong> Vision-based automation of hunting flows</li>
          <li><strong>Python Scripting:</strong> Real-time control logic for timing, items, decisions</li>
          <li><strong>Rooted Android:</strong> Elevated permissions for GPS spoofing</li>
          <li><strong>GameGuardian:</strong> Address-based memory inspection for weapon stats</li>
          <li><strong>APK reverse engineering:</strong> Decompiled client for hidden assets/keys (educational)</li>
        </ul>
        <p>
          The system could <strong>hunt all monsters automatically</strong>. I was among the earliest to reach
          <strong>max level and a complete weapon collection</strong> via scripting and reverse engineering.
        </p>
      </div>
    </div>

    <div class="project">
      <img src="static/img/course_project.png" alt="Course Projects" />
      <div class="project-content">
        <h3 class="project-title">Misc. Projects</h3>
        CG: Computer Graphics, ML: Machine Learning, DL: Deep Learning, CV: Computer Vision
        <ul class="project-list">
          <li>
            <strong>CG: Ray Tracer</strong> — Implemented a ray tracing engine from scratch, supporting recursive reflections, refractions, Phong shading, and multiple light sources.  
            <em>Tech:</em> C++, OpenGL (for preview), image output to PPM.
          </li>
          <li>
            <strong>App Development: 2048 Game (Android)</strong> — Implemented both <em>touch</em> swipes and <em>sensor</em> control:
            shake/tilt in each direction to trigger moves, using the device <strong>accelerometer</strong> with a
            high-pass filter to detect directional impulses. Smooth animations and score/undo included.
            <em>Tech:</em> Java (Android Studio), SensorManager (Accelerometer), View animations.
          </li>
          <li>
            <strong>Verilog: FPGA Music Player</strong> — Designed and implemented a music playback system on an FPGA, including audio decoding, playback control, and hardware-level I/O for buttons and LEDs.  
            <em>Tech:</em> Verilog, Quartus Prime, Altera DE2 board.
          </li>
          <li>
            <strong>Verilog: Kirsch Edge Detection</strong> — Implemented the Kirsch operator in Verilog for 8-directional edge detection on grayscale images, optimized for high-throughput processing in FPGA-based systems.
            <em>Tech:</em> Verilog, FPGA design, hardware optimization, image processing algorithms
          </li>
          <li>
            <strong>ML/DL: Prediction of Gait Freezing in Parkinson’s Disease</strong> — Built machine learning models (LSTM and CNN) to detect and predict gait freezing episodes from wearable sensor data in PD patients.  
            Achieved competitive accuracy in classification tasks and evaluated models with confusion matrices and ROC curves.  
            <em>Tech:</em> MATLAB, Deep Learning Toolbox.
          </li>
          <li>
            <strong>Robotics: Music-Following Robot</strong> — A line-following robot that converts varying grayscale levels into corresponding sound frequencies, integrating motion control with auditory feedback.
            <em>Tech:</em> Arduino programming, hardware design (MOSFET, motors), sensor integration, algorithm design
          </li>
          <li>
            <strong>ML/CV: Semantic Segmentation</strong> — Developed computer vision pipeline to classify each pixel into semantic categories, enabling scene understanding for downstream robotics tasks.
            <em>Tech:</em> Python, OpenCV, PyTorch
          </li>
          <li>
            <strong>CV: Object Contour Detection & Following</strong> — Implemented contour detection to identify and track object boundaries in real time, integrating with motion control for robotic following.
            <em>Tech:</em> Python, OpenCV, edge detection, contour extraction
          </li>

        </ul>
      </div>
    </div>
  </section>
</body>
</html>
